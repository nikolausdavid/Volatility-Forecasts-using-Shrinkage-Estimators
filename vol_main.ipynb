{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5f16f9db-ff31-4d4f-aef4-a79dc9aca8ca",
   "metadata": {},
   "source": [
    "# Volatility Forecasting in FX Markets with Shrinkage Estimators\n",
    "**Core Class Implementation for Data Engineering, Model Estimation and Evaluation**\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "**Author:** David Harrieder\n",
    "**Supervisor:** Prof. Dr. Daniel Rösch \n",
    "**University:** University of Regensburg\n",
    "**Date:** July 2025  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ed5ef2-a07d-4652-a25c-bf312548a9de",
   "metadata": {},
   "source": [
    "#### Imports & Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9dcf579e-d698-4fe8-b874-218d86402418",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import re\n",
    "import warnings\n",
    "from dataclasses import dataclass, field\n",
    "from itertools import cycle\n",
    "from typing import Any, Dict, List, Literal, Tuple\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.stattools import durbin_watson, jarque_bera\n",
    "from sklearn.linear_model import (\n",
    "    Lasso,\n",
    "    LassoCV,\n",
    "    LassoLars,\n",
    "    LinearRegression,\n",
    "    lars_path,\n",
    ")\n",
    "from sklearn.metrics import (\n",
    "    mean_absolute_error,\n",
    "    mean_absolute_percentage_error,\n",
    "    mean_squared_error,\n",
    "    r2_score,\n",
    ")\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ff4932c-6e79-43cf-9afe-f9487c7069bf",
   "metadata": {},
   "source": [
    "# Main Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5d456cf-064c-4d32-bdaa-f1575be4d1ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UnifiedVolForecast:\n",
    "    def __init__(self, df, target_col=\"RV\", model_type=\"HAR\", flex_threshold=100, lasso_cv=10, lasso_max_iter=100000):\n",
    "        self.df = df.copy()\n",
    "        self.target_col = target_col\n",
    "        self.model_type = model_type.upper()\n",
    "        self.flex_threshold = flex_threshold\n",
    "        self.lasso_cv = lasso_cv\n",
    "        self.lasso_max_iter = lasso_max_iter\n",
    "        #\n",
    "        self.forecasts = {}\n",
    "        self.results = {}\n",
    "        self.lasso_nonzero_coefs = {} \n",
    "\n",
    "    # HELPER FUNCTIONS\n",
    "    \n",
    "    def _mincer_zarnowitz_r2(self, y_true, y_pred):\n",
    "        mask = np.isfinite(y_true) & np.isfinite(y_pred)\n",
    "        y_true = y_true[mask]\n",
    "        y_pred = y_pred[mask]\n",
    "        if len(y_true) == 0:\n",
    "            return np.nan  # Keine gültigen Werte vorhanden\n",
    "        y_true = y_true.reshape(-1, 1)\n",
    "        y_pred_const = sm.add_constant(y_pred)\n",
    "        model = sm.OLS(y_true, y_pred_const).fit()\n",
    "        return model.rsquared\n",
    "\n",
    "    def _tewma(self, series, span, kappa=0.94):\n",
    "        raw_weights = [(1 - kappa) * (kappa ** i) for i in range(span)]\n",
    "        raw_weights = np.array(raw_weights)\n",
    "        normalization = 1 - kappa ** span\n",
    "        weights = raw_weights / normalization\n",
    "        weights = weights[::-1]\n",
    "        return series.rolling(window=span).apply(lambda x: np.dot(weights, x), raw=True)\n",
    "\n",
    "    # FEATURE GENERATION        \n",
    "\n",
    "    def _generate_features(self, df):\n",
    "        if self.model_type == \"HAR\":\n",
    "            df[\"lag1\"] = df[self.target_col].shift(1)\n",
    "            df[\"lag5\"] = df[self.target_col].rolling(5).mean().shift(1)\n",
    "            df[\"lag22\"] = df[self.target_col].rolling(22).mean().shift(1)\n",
    "            return df.dropna(), [\"lag1\", \"lag5\", \"lag22\"]\n",
    "\n",
    "        elif self.model_type == \"HEXP\":\n",
    "            df[\"tewma_1\"] = self._tewma(df[self.target_col].shift(1), 1)\n",
    "            df[\"tewma_5\"] = self._tewma(df[self.target_col].shift(1), 5)\n",
    "            df[\"tewma_22\"] = self._tewma(df[self.target_col].shift(1), 22)\n",
    "            return df.dropna(), [\"tewma_1\", \"tewma_5\", \"tewma_22\"]\n",
    "\n",
    "        elif self.model_type == \"LASSO-HAR\":\n",
    "            rolling_means = pd.concat({\n",
    "                f\"mean_{w}\": df[self.target_col].rolling(w).mean().shift(1)\n",
    "                for w in range(1, self.flex_threshold + 1)\n",
    "            }, axis=1)\n",
    "            df_ext = pd.concat([df, rolling_means], axis=1).dropna()\n",
    "            return df_ext, rolling_means.columns.tolist()\n",
    "\n",
    "        elif self.model_type == \"LASSO-HEXP\":\n",
    "            tewmas = pd.concat({\n",
    "                f\"tewma_{s}\": self._tewma(df[self.target_col].shift(1), s)\n",
    "                for s in range(1, self.flex_threshold + 1)\n",
    "            }, axis=1)\n",
    "\n",
    "            df_ext = pd.concat([df, tewmas], axis=1).dropna()\n",
    "            return df_ext, tewmas.columns.tolist()\n",
    "\n",
    "    # LASSO MODEL ESTIMATION GETTER\n",
    "    \n",
    "    def _get_model(self):\n",
    "        if self.model_type.startswith(\"LASSO\"):\n",
    "            return LassoCV(\n",
    "                cv=TimeSeriesSplit(n_splits=self.lasso_cv),\n",
    "                n_jobs=-1,\n",
    "                fit_intercept=True,\n",
    "                positive=True,\n",
    "                max_iter=self.lasso_max_iter\n",
    "            )\n",
    "        else:\n",
    "            return LinearRegression(fit_intercept=True, positive=True)\n",
    "\n",
    "\n",
    "    # IN-SAMPLE EVALUATION\n",
    "            \n",
    "    def in_sample_fit(self):\n",
    "        df_feat, feature_cols = self._generate_features(self.df)\n",
    "        if not self.model_type.startswith(\"LASSO\"):\n",
    "            offset = max(self.flex_threshold - 22, 0)\n",
    "            df_feat = df_feat.iloc[offset:]\n",
    "            print(f\"Offset for In-Sample at {self.model_type}: Trim {offset} rows\")\n",
    "            \n",
    "        X = df_feat[feature_cols]\n",
    "        y = df_feat[self.target_col].values\n",
    "        scaler = StandardScaler().fit(X)\n",
    "        X_scaled = scaler.transform(X)\n",
    "        model = self._get_model()\n",
    "        model.fit(X_scaled, y)\n",
    "        y_pred = model.predict(X_scaled)\n",
    "\n",
    "        \n",
    "\n",
    "        print(f\"In-Sample period: {df_feat.index[0].date()} bis {df_feat.index[-1].date()}\")\n",
    "\n",
    "        from statsmodels.api import OLS, add_constant\n",
    "\n",
    "        if self.model_type.startswith(\"LASSO\"):\n",
    "            coefs = model.coef_\n",
    "            \n",
    "            non_zero_mask = coefs != 0\n",
    "            surviving_vars = [feature_cols[j] for j, nz in enumerate(non_zero_mask) if nz]\n",
    "            surviving_X = X_scaled[:, non_zero_mask]\n",
    "            X_ols = add_constant(surviving_X)\n",
    "            ols_model = OLS(y, X_ols).fit()\n",
    "            ols_coefs = ols_model.params[1:]\n",
    "            ols_pvals = ols_model.pvalues[1:]\n",
    "            adj_r2 = ols_model.rsquared_adj\n",
    "            signif = ols_pvals < 0.05\n",
    "            self.in_sample_model_details = pd.DataFrame({\n",
    "                \"Variable\": [\"Intercept\"] + surviving_vars,\n",
    "                \"Coefficient\": [f\"{ols_model.params[0]:.4e}\"] + [f\"{val:.4e}\" for val in ols_coefs],\n",
    "                \"P-Value\": [ols_model.pvalues[0]] + list(ols_pvals),\n",
    "                \"Significant_5pct\": [ols_model.pvalues[0] < 0.05] + list(signif)\n",
    "            })\n",
    "\n",
    "            self.lasso_nonzero_coefs = {\n",
    "                \"in_sample\": dict(zip(surviving_vars, coefs[non_zero_mask]))\n",
    "            }\n",
    "        else:\n",
    "            X_ols = add_constant(X_scaled)\n",
    "            ols_model = OLS(y, X_ols).fit()\n",
    "            coefs = ols_model.params\n",
    "            pvals = ols_model.pvalues\n",
    "            adj_r2 = ols_model.rsquared_adj\n",
    "            signif = pvals < 0.05\n",
    "            self.in_sample_model_details = pd.DataFrame({\n",
    "                \"Variable\": [\"Intercept\"] + feature_cols,\n",
    "                \"Coefficient\": [f\"{coefs[0]:.4e}\"] + [f\"{val:.4e}\" for val in coefs[1:]],\n",
    "                \"P-Value\": [pvals[0]] + list(pvals[1:]),\n",
    "                \"Significant_5pct\": [pvals[0] < 0.05] + list(pvals[1:] < 0.05)\n",
    "            })\n",
    "\n",
    "\n",
    "        df_insample = pd.DataFrame({\n",
    "            \"realized\": y,\n",
    "            \"forecast\": y_pred\n",
    "        }, index=df_feat.index)\n",
    "\n",
    "        self.forecasts[\"in_sample\"] = df_insample\n",
    "        eval_metrics = self.evaluate_forecasts()\n",
    "        eval_metrics[\"in_sample\"][\"Adjusted_R2\"] = adj_r2\n",
    "        return eval_metrics\n",
    "\n",
    "    # ROLLING FORECAST FRAMEWORK        \n",
    "\n",
    "    def rolling_forecast(self, window_size=1000, horizon=1, step_size=1):\n",
    "        df_feat, feature_cols = self._generate_features(self.df)\n",
    "\n",
    "        offset = 0\n",
    "        if not self.model_type.startswith(\"LASSO\"):\n",
    "            offset = max(self.flex_threshold - 22, 0)\n",
    "            df_feat = df_feat.iloc[offset:]\n",
    "            print(f\"Offset at {self.model_type}: shorten by {offset} (flex_threshold={self.flex_threshold})\")\n",
    "        else:\n",
    "            print(f\"No offset applied at {self.model_type} (LASSO-Modell)\")\n",
    "\n",
    "        print(f\"Remaining length: {len(df_feat)}\")\n",
    "\n",
    "        forecasts = []\n",
    "        reals = []\n",
    "        valid_dates = []\n",
    "\n",
    "        if self.model_type.startswith(\"LASSO\"):\n",
    "            coef_dict = {}\n",
    "\n",
    "        first_valid_index = None\n",
    "\n",
    "        for i in range(window_size, len(df_feat) - horizon + 1, step_size):\n",
    "            train = df_feat.iloc[i - window_size:i]\n",
    "            test = df_feat.iloc[i:i + horizon]\n",
    "            X_train = train[feature_cols]\n",
    "            y_train = train[self.target_col].values\n",
    "            scaler = StandardScaler().fit(X_train)\n",
    "            X_train_scaled = scaler.transform(X_train)\n",
    "            model = self._get_model()\n",
    "            model.fit(X_train_scaled, y_train)\n",
    "\n",
    "            if self.model_type.startswith(\"LASSO\"):\n",
    "                coefs = model.coef_\n",
    "                non_zero = {feature_cols[j]: coefs[j] for j in range(len(coefs)) if coefs[j] != 0}\n",
    "                date_key = df_feat.index[i].strftime(\"%Y-%m-%d\")\n",
    "                coef_dict[date_key] = non_zero\n",
    "\n",
    "            X_test = test[feature_cols].iloc[:horizon]\n",
    "            y_test = test[self.target_col].iloc[:horizon]\n",
    "            if X_test.isnull().values.any() or y_test.isnull().any():\n",
    "                continue\n",
    "            X_test_scaled = scaler.transform(X_test)\n",
    "            y_pred = model.predict(X_test_scaled)\n",
    "            forecasts.append(y_pred.sum())\n",
    "            reals.append(y_test.sum())\n",
    "            valid_dates.append(df_feat.index[i])\n",
    "\n",
    "            if first_valid_index is None:\n",
    "                print(f\"First Rolling-Window starts: {train.index[0].date()} bis {train.index[-1].date()}\")\n",
    "                print(f\"First Forecast for: {df_feat.index[i].date()}\")\n",
    "                first_valid_index = i\n",
    "\n",
    "        if len(forecasts) > 0:\n",
    "            df_h = pd.DataFrame({\n",
    "                f\"realized_{horizon}d\": reals,\n",
    "                f\"forecast_{horizon}d\": forecasts\n",
    "            }, index=valid_dates)\n",
    "            self.forecasts[f\"{horizon}d\"] = df_h\n",
    "        else:\n",
    "            print(f\"No valid forecasts for horizon: {horizon}\")\n",
    "            df_h = pd.DataFrame()\n",
    "\n",
    "        if self.model_type.startswith(\"LASSO\"):\n",
    "            self.lasso_nonzero_coefs = coef_dict\n",
    "\n",
    "        df_h[f\"residual_{horizon}d\"] = df_h[f\"realized_{horizon}d\"] - df_h[f\"forecast_{horizon}d\"]\n",
    "        return df_h\n",
    "\n",
    "    # OUT-OF-SAMPLE EVALUATION\n",
    "    \n",
    "    def evaluate_forecasts(self):\n",
    "        results = {}\n",
    "        for horizon, df in self.forecasts.items():\n",
    "            rv = df.iloc[:, 0].values\n",
    "            f = df.iloc[:, 1].values\n",
    "            mask = (rv > 0) & (f > 0)\n",
    "            rv, f = rv[mask], f[mask]\n",
    "            mse = mean_squared_error(rv, f)\n",
    "            mae = mean_absolute_error(rv, f)\n",
    "            if np.any(rv <= 0) or np.any(f <= 0):\n",
    "                print(\"WARNING: At least one value in 'rv' is ≤ 0. QLIKE might be biased\")\n",
    "            ratio = np.where((rv > 0) & (f > 0), rv / f, np.nan)\n",
    "            log_ratio = np.log(ratio, out=np.full_like(ratio, np.nan), where=(ratio > 0))\n",
    "            qlike_val = np.nanmean(ratio - log_ratio - 1)\n",
    "            r2 = r2_score(rv, f)\n",
    "            mz_r2 = self._mincer_zarnowitz_r2(rv, f)\n",
    "            dw = durbin_watson(rv - f)\n",
    "            results[horizon] = {\n",
    "                \"MSE\": mse,\n",
    "                \"RMSE\": np.sqrt(mse),\n",
    "                \"MAE\": mae,\n",
    "                \"QLIKE\": qlike_val,\n",
    "                \"R2\": r2,\n",
    "                \"R2_MincerZarnowitz\": mz_r2,\n",
    "                \"Durbin_Watson\": dw\n",
    "            }\n",
    "        self.results = results\n",
    "        return results\n",
    "\n",
    "    # PLOTS\n",
    "    \n",
    "    def plot_forecast(self, horizon):\n",
    "        df = self.forecasts.get(horizon)\n",
    "        if df is None:\n",
    "            print(f\"No forecasting horizon found for horizon: {horizon}\")\n",
    "            return\n",
    "        fig, ax = plt.subplots(figsize=(14, 3), dpi=600)\n",
    "        ax.plot(df.index, df.iloc[:, 0], label=\"Realized\", color=\"black\", lw=1, )\n",
    "        ax.plot(df.index, df.iloc[:, 1], label=\"Forecast\", color=\"red\", lw=1)\n",
    "        ax.set_ylabel(\"RV\")\n",
    "        ax.set_title(f\"{self.model_type} - {horizon}\")\n",
    "        ax.ticklabel_format(axis='y', style='sci', scilimits=(0,0))\n",
    "        plt.show()\n",
    "    \n",
    "    \n",
    "    def plot_in_sample(self):\n",
    "        df = self.forecasts.get(\"in_sample\")\n",
    "        if df is None:\n",
    "            print(\"No available In-sample fit.\")\n",
    "            return\n",
    "        fig, ax = plt.subplots(figsize=(14, 4), dpi=600)\n",
    "        ax.plot(df.index, df.iloc[:, 0], label=\"Realized\", color=\"black\", lw=1)\n",
    "        ax.plot(df.index, df.iloc[:, 1], label=\"Forecast\", color=\"red\", lw=1)\n",
    "        ax.set_ylabel(\"RV\")\n",
    "        ax.set_title(f\"{self.model_type} - 1d\")\n",
    "        ax.ticklabel_format(axis='y', style='sci', scilimits=(0,0)) \n",
    "        plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
